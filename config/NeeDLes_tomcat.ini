[input_output_paths]
#The file containing all issues data
its_file_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat.xls

#The software project directory path
project_dir_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat

#The directory storing code index
code_index_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_index

#The file storing all code contents
code_contents_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_code_content

#The file storing all bug contents
bug_contents_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_bug_content

#The file storing positive/negative pairs between bug index and code index
file_oracle_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_oracle

#The file storing changed methods for each commit
code_mappings_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_mappings_code

#The file storing all relevant methods for each bug
method_oracle_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/data/Tomcat/Tomcat_relevant_methods

#The directory storing neural network structures and weights
model_dir_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/model/model_tomcat

#The file containing evaluation results
evaluation_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/eval/eval_tomcat

word2vec_model_path = C:/Users/dell/Documents/PythonProjects/NeeDLes/word2vec/GoogleNews-vectors-negative300.bin

[oracle_generator]

#The field of bug taken into consideration, could only be description, summary or both
issue_field = both

#The number of negative samples
#Given a bug, the codes with the highest Lucene TFIDFsimilarity scores are selected as the negative samples
neg_sample_number = 5

##### text preprocessing options #####
# whether to split camel case
split_camel_case = true

# whether to transform to lower case
to_lower_case = true

# whether to stem
stem = true

# whether to remove stop words
stop_word_remove = true

#whether to filter word by length
filter_word_length = true

#if yes, length less than this value will be filtered out
min_word_length = 2

#if yes, length greater than this value will be filtered out
max_word_length = 12

#whether to keep punctuations
keep_punctuation = true

##### program parsing options ###

# whether to keep imported packages for each source code file.
# if yes, use "\t" to split imported packages and the code contents
import_packages = false

# whether to split file into methods
# if yes, use "\t" to split methods
split_into_methods = true

# whether to keep comments for each method
keep_comments = true


[oracle_reader]
# the vocabulary size
vocabulary_size = 300

# the first split_ratio of bugs are used to train the model
split_ratio = 0.8

# the input lstm length, each bug and code sequence is zero-padded or truncated to this length
lstm_seq_length = 50

# the embedding dimension
embedding_dimension = -1

word2vec = True

[network_structure]
# the lstm unit length
lstm_core_length = 32

# the activation function for lstm output
activation_function = tanh

# the activation function for lstm input
inner_activation_function = hard_sigmoid

# the function measuring bug and code distance
distance_function = cos

# the initialization function for lstm input
initializer = glorot_uniform

# the initialization function for lstm inner elements
inner_initializer = orthogonal

# the regularizer for weights
#regularizer = l1

[training_options]
##### optimizer options #####

optimizer = RMSprop

learning_rate = 0.0001

epsilon = 1e-8

decay = 0.0

rho_1 = 0.9

#dropout_rate for lstm unit
dropout = 0.8

#number of training epochs
nb_epoch = 100

[evaluation_options]
# number of k for the top-k metric
k_value = 10

#the threshold for judging relevance, for precision and recall metrics
rel_threshold = 0.65

