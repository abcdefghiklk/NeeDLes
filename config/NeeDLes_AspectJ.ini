[input_output_paths]
#The file containing all issues data
its_file_path = ../data/AspectJ/AspectJ.xls

#The software project directory path
project_dir_path = ../data/AspectJ/AspectJ

#The directory storing code index
code_index_path = ../data/AspectJ/AspectJ_index

#The file storing all code contents
code_contents_path = ../data/AspectJ/AspectJ_code_content

#The file storing all bug contents
bug_contents_path = ../data/AspectJ/AspectJ_bug_content

#The file storing positive/negative pairs between bug index and code index
file_oracle_path = ../data/AspectJ/AspectJ_oracle

#The file storing changed methods for each commit
code_mappings_path = ../data/AspectJ/AspectJ_mappings_context_new ../data/AspectJ/AspectJ_mappings_context_old

#The file storing all relevant methods for each bug
sequence_oracle_path = ../data/AspectJ/AspectJ_relevant_methods

#The directory storing neural network structures and weights
model_dir_path = ../model/model_aspectj

#The directory containing prediction results
prediction_dir_path = ../eval/pred_aspectj

#The file containing evaluation results
evaluation_path = ../eval/eval_aspectj

#The file storing word2vec model
word2vec_model_path = ../word2vec/vec_hybrid_100

[oracle_generator]

#The field of bug taken into consideration, could only be description, summary or both
issue_field = both

code_mappings_type = context

#The number of negative samples
#Given a bug, the codes with the highest Lucene TFIDFsimilarity scores are selected as the negative samples
neg_sample_number = 5

##### text preprocessing options #####
# whether to split camel case
split_camel_case = true

# whether to transform to lower case
to_lower_case = true

# whether to stem
stem = false

# whether to remove stop words
stop_word_remove = true

#whether to filter word by length
filter_word_length = true

#if yes, length less than this value will be filtered out
min_word_length = 2

#if yes, length greater than this value will be filtered out
max_word_length = 12

#whether to keep punctuations
keep_punctuation = false

##### program parsing options ###

# whether to keep imported packages for each source code file.
# if yes, use "\t" to split imported packages and the code contents
import_packages = false

# whether to split file into methods
# if yes, use "\t" to split methods
split_into_methods = true

# whether to keep comments for each method
keep_comments = true


[oracle_reader]
# the vocabulary size
vocabulary_size = 100

# the first split_ratio of bugs are used to train the model
split_ratio = 0.8

# the input lstm length, each bug and code sequence is zero-padded or truncated to this length
lstm_seq_length = 50

# the embedding dimension
embedding_dimension = -1

word2vec = True

sample_num = 50

[network_structure]
# the lstm unit length
lstm_core_length = 32

# the activation function for lstm output
activation_function = tanh

# the activation function for lstm input
inner_activation_function = hard_sigmoid

# the function measuring bug and code distance
distance_function = cos

# the initialization function for lstm input
initializer = glorot_uniform

# the initialization function for lstm inner elements
inner_initializer = orthogonal

# the regularizer for weights
#regularizer = l1

[training_options]
##### optimizer options #####

optimizer = Adam

learning_rate = 0.0001

epsilon = 1e-8

decay = 0.0

rho_1 = 0.9

#dropout_rate for lstm unit
dropout = 0.5

#number of training epochs
nb_epoch = 20

[evaluation_options]
# number of k for the top-k metric
k_value = 10

#the threshold for judging relevance, for precision and recall metrics
rel_threshold = 0.65

